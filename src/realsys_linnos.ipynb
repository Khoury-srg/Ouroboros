{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: method definition for is_polyhedral at /home/mlsys23/.julia/packages/LazySets/HlinV/src/LazyOperations/Complement.jl:53 declares type variable N but does not use it.\n",
      "WARNING: method definition for convert at /home/mlsys23/.julia/packages/LazySets/HlinV/src/convert.jl:179 declares type variable N but does not use it.\n",
      "WARNING: method definition for issubset at /home/mlsys23/.julia/packages/LazySets/HlinV/src/ConcreteOperations/issubset.jl:609 declares type variable N but does not use it.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from numpy.core.numeric import Inf\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from NNet.utils.writeNNet import writeNNet\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "import time\n",
    "import importlib\n",
    "import models\n",
    "import datasets\n",
    "import math\n",
    "import utils\n",
    "from utils import *\n",
    "import tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.LinnosDataset object at 0x7ff78a285c50>\n",
      "LinnosTask00000-1_300\n",
      "data size:  47895\n",
      "model size: 365.629KB\n",
      "latency time (us): 88.77328\n",
      "throughput: 158423.67159\n",
      "accuracy: 0.998475833\n",
      "l2 error: 0.000139140\n"
     ]
    }
   ],
   "source": [
    "def to_device(data, device):\n",
    "    return tuple(tensor.to(device) for tensor in data) if isinstance(data, tuple) else data.to(device)\n",
    "def test(model, data, batch_size, compute_loss, verbose=False, compute_error=False):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    digit_size, digit_correct = 0, 0\n",
    "    positive = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = to_device(X, \"cuda\")\n",
    "            y = to_device(y, \"cuda\")\n",
    "            if compute_error:\n",
    "                acc_cnt, loss = compute_loss(model, X, y)\n",
    "                test_loss += loss.cpu().item() if torch.is_tensor(loss) else loss\n",
    "                correct += acc_cnt.cpu().item() if torch.is_tensor(acc_cnt) else acc_cnt\n",
    "    if not compute_error:\n",
    "        return None, None\n",
    "    test_loss /= num_batches\n",
    "    acc = correct * 1. / size\n",
    "    if verbose:\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*acc):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return acc, test_loss\n",
    "    \n",
    "def accuracy_comparison(task_class, time_out, verified):\n",
    "\n",
    "    training_data = datasets.LinnosDataset(\"../data/linnos/linnos.csv\", test=False)\n",
    "    print(training_data)\n",
    "    task = task_class(add_counterexample = verified, incremental_training = verified, batch_counterexample = verified, early_rejection = verified, time_out=time_out) # wo finetune\n",
    "    task.load_model(\"../model/\"+task.save_name+\".pth\")\n",
    "\n",
    "    print(task.save_name)\n",
    "    print(\"data size: \", len(training_data))\n",
    "    param_size = 0\n",
    "    for param in task.model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    print('model size: {:.3f}KB'.format(param_size / 1024))\n",
    "    def eval_loss(model, X, y):\n",
    "        # normal_X, counter_X = X\n",
    "        # normal_y, counter_y = y\n",
    "        normal_X = X\n",
    "        normal_y = y\n",
    "        normal_acc_cnt, normal_loss = task.compute_normal_loss(model, normal_X, normal_y)\n",
    "        return normal_acc_cnt, normal_loss\n",
    "\n",
    "    task.model = task.model.to(\"cuda\")\n",
    "    task.model.eval()\n",
    "\n",
    "    ### latency ###\n",
    "    batch_size=1\n",
    "    start = time.time()\n",
    "    acc, loss = test(task.model, training_data, batch_size, eval_loss, compute_error=False)\n",
    "    end = time.time()\n",
    "    print(\"latency time (us): {:.5f}\".format((end - start)/len(training_data)*1e6))\n",
    "    # print(\"accuracy: {:.9f}\".format(acc))\n",
    "    # print(\"l2 error: {:.9f}\".format(loss))\n",
    "    \n",
    "    ### throughput ###\n",
    "    start = time.time()\n",
    "    rep_times = 100\n",
    "    batch_size = len(training_data)\n",
    "    for t in range(rep_times):\n",
    "        acc, loss = test(task.model, training_data, batch_size, eval_loss, compute_error=False)\n",
    "    end = time.time()\n",
    "    print(\"throughput: {:.5f}\".format(len(training_data)/((end - start)/rep_times)))\n",
    "\n",
    "    acc, loss = test(task.model, training_data, batch_size, eval_loss, compute_error=True)\n",
    "    print(\"accuracy: {:.9f}\".format(acc))\n",
    "    print(\"l2 error: {:.9f}\".format(loss))\n",
    "    \n",
    "accuracy_comparison(tasks.LinnosTask, 300, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datasets.LinnosDataset object at 0x7ff78a251da0>\n",
      "LinnosTask11110-1_300\n",
      "data size:  47895\n",
      "model size: 365.629KB\n",
      "latency time (us): 76.53733\n",
      "throughput: 170820.04905\n",
      "accuracy: 0.998308801\n",
      "l2 error: 0.000080312\n"
     ]
    }
   ],
   "source": [
    "accuracy_comparison(tasks.LinnosTask, 300, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47895, 9)\n",
      "1.0\n",
      "0.0\n",
      "0.00701667\n",
      "0.00058624975\n",
      "Train Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.555961 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.548972 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.0%, Avg loss: 0.547561 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.547266 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.546476 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.545423 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.545082 \n",
      "\n",
      "Train Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.545065 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(model, data, batch_size, compute_loss, verbose=False):\n",
    "    device = \"cuda\"\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0, 0\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = to_device(X, device)\n",
    "        y = to_device(y, device)\n",
    "        acc_cnt, loss = compute_loss(model, X, y)\n",
    "        # print(acc_cnt, \"/\", len(X))\n",
    "        correct += acc_cnt.cpu().item() if torch.is_tensor(acc_cnt) else acc_cnt\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.cpu().item() if torch.is_tensor(loss) else loss\n",
    "        # if verbose and batch % 10 == 0:\n",
    "        #     loss, current = loss.item(), batch * len(X)\n",
    "        #     print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    train_loss /= num_batches\n",
    "    acc = correct * 1. / size\n",
    "    if verbose:\n",
    "        print(f\"Train Error: \\n Accuracy: {(100*acc):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "    return acc, train_loss\n",
    "\n",
    "def baseline():\n",
    "    model = models.FC(1, 9, 256, 2)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    def compute_loss(model, x, y):\n",
    "        y = y.squeeze(dim=1)\n",
    "        pred = model(x)\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        # print(pred.argmax(1))\n",
    "        acc_cnt = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        # print(acc_cnt)\n",
    "        # assert False\n",
    "        loss = loss_fn(pred, y)\n",
    "        return acc_cnt, loss\n",
    "\n",
    "    training_data = datasets.LinnosDataset(\"../data/linnos/linnos.csv\", test=False)\n",
    "    print(np.shape(training_data.xs))\n",
    "    print(np.max(training_data.ys))\n",
    "    print(np.min(training_data.ys))\n",
    "    print(np.mean(training_data.ys))\n",
    "    print(np.median(training_data.ys))\n",
    "    threshold = np.median(training_data.ys)\n",
    "    training_data.ys = training_data.ys > threshold\n",
    "    training_data.ys = training_data.ys.astype(int)\n",
    "    for ep in range(100):\n",
    "        acc, train_loss = train(model, training_data, 7, compute_loss, verbose=True)\n",
    "\n",
    "baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ouroboros",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
